\section{Other Concerns}

    Upto date, memory consistency models are still lacking a very user-friendly specification for use by many programmers. 
    In addition to this, we also showed that related work existed exposing limitations in many models with respect to basic program transformations.
    
    There is also the big question of compilation; whether the compilation from source and target with different memory models is correct? This question is also quite open ended. While we did not do literature reivew in this direction particularly, works done by Lahav et.al~\cite{Lahav} and Watt et.al~\cite{Watt} on the C11 and JavaScript memory model respectively exposed incorrect compilation done due to which the program exhibited unintended behaviors on execution. 
    The interested reader can refer to (INSERT IMM LINK HERE FROM VIKTOR'S SITE) to explore further in this direction.
    
    Many memory models face the concern which is notoriously known as \textit{out-of-thin-air}; a program can give an outcome that is not supposed to have existed in any observable behaviors as per the semantics. %PErhaps give an example here 
    Such behaviors have been shown to be in programs that exhibit \textit{data-races} in their executions.
    The C11 memory model escapes from addressing it by stating that any program with \textit{data-races} has undefined behavior.
    Java on the other hand, relies on a complicated semantics to guarantee that no \textit{out-of-thin-air} values can exist in programs with \textit{data-races}. This to date is still very complicated and subtle to understand in order to use it properly in programs. 
    While this may seem that \textit{out-of-thin-air} is a bad property that must be avoided at all costs, Verbrugge et.al~\cite{Verbrugge} showed that disallowing them also disallows quite a few compiler optimizations.

    We also explored certain works that came up with their own memory model in order to simplify the problems above that may arise due to it. 
    Arvind et.al~\cite{Arvind} presented a novel framework to specify memory models using Instruction Reordering and Store atomicity. This work in our eyes, was a better representation of intended behaviors that should be allowed by a memory model. 
    Marino et.al~\cite{Marino} proposed a new memory model named \textit{DRFx}, which they claimed to be quite intuitive for programmers as well as allowing many of the program transformations responsible for major performance benefits.
    Kang et.al~\cite{Kang} proposed a new memory model referred to as \textit{Promising Semantics} to address the well known out-of-thin-air problem that exists in current memory models. Though the semantics of this model, in our experience is quite complex and not so user-friendly.
